{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "refined-marking",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Lambda, Flatten\n",
    "from sklearn.preprocessing import Normalizer, LabelEncoder\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from numpy import asarray, expand_dims\n",
    "from keras_vggface.utils import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import cv2\n",
    "from collections import defaultdict\n",
    "from numpy import argsort\n",
    "from numpy import load\n",
    "from tensorflow.keras.models import load_model\n",
    "from numpy import save, load, savez_compressed\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "finnish-religion",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function which takes old model as input and adds one more output node and returns a new model\n",
    "def updateModel(model):\n",
    "    # creating a new model\n",
    "    model_2 = Sequential()\n",
    "\n",
    "    # getting all the layers except the output one\n",
    "    for layer in model.layers[:-1]: # just exclude last layer from copying\n",
    "        model_2.add(layer)\n",
    "\n",
    "    # prevent the already trained layers from being trained again \n",
    "    # (you can use layers[:-n] to only freeze the model layers until the nth layer)\n",
    "    # for layer in model_2.layers:\n",
    "    #     layer.trainable = False\n",
    "\n",
    "    # adding the new output layer, the name parameter is important \n",
    "    # otherwise, you will add a Dense_1 named layer, that normally already exists, leading to an error\n",
    "    num_cats = model.get_layer(index = -1).get_config()['units']\n",
    "    model_2.add(Dense(num_cats+1, name = 'new_Dense', input_shape=(512,), kernel_initializer = 'he_uniform', activation = 'softmax'))\n",
    "    model_2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "addressed-acoustic",
   "metadata": {},
   "outputs": [],
   "source": [
    "#funtion which takes old model, dataset and new data. adds to the original dataset and updates it\n",
    "def addNewLabel(modelL, modelR, trainX, trainy, testX, testy, new_data):\n",
    "    #load new dataset\n",
    "    trainX2, trainy2, testX2, testy2 = new_data\n",
    "\n",
    "    trainX, trainy, testX, testy = list(trainX), list(trainy), list(testX), list(testy)\n",
    "    trainX2, trainy2, testX2, testy2 = list(trainX2), list(trainy2), list(testX2), list(testy2)\n",
    "\n",
    "    trainy += trainy2\n",
    "    trainX += trainX2\n",
    "    testy += testy2\n",
    "    testX += testX2\n",
    "    \n",
    "    modelL = updateModel(modelL)\n",
    "    modelR = updateModel(modelR)\n",
    "    return modelL, modelR, trainX, trainy, testX, testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "wrapped-sequence",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize input vectors and numerize the labels.\n",
    "def encodeLabels(trainX, trainy, testX, testy):\n",
    "\t# normalize input vectors\n",
    "\tin_encoder = Normalizer(norm='l2')\n",
    "\ttrainX = in_encoder.transform(trainX)\n",
    "\ttestX = in_encoder.transform(testX)\n",
    "\t# label encode targets\n",
    "\tout_encoder = LabelEncoder()\n",
    "\tout_encoder.fit(sorted(trainy, key = lambda x: int(x.split('_')[0])))\n",
    "    #print(sorted(testy, key = lambda x: int(x.split('_')[0])))\n",
    "\ttrainy = out_encoder.transform(sorted(trainy, key = lambda x: int(x.split('_')[0])))\n",
    "    #print(trainy)\n",
    "\ttesty = out_encoder.transform(sorted(testy, key = lambda x: int(x.split('_')[0])))\n",
    "    #print(testy)\n",
    "\treturn trainX, trainy, testX, testy, out_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "upset-break",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to incerase the number of images of a class by a given number\n",
    "def extendDataset(image_folder_path, extend_by):\n",
    "    parent = image_folder_path\n",
    "    X = []\n",
    "    y = []\n",
    "    i = 0\n",
    "\n",
    "    image_gen = ImageDataGenerator(rotation_range=5,\n",
    "                                   rescale = False,\n",
    "                                   shear_range = 0.2,\n",
    "                                   fill_mode='reflect',\n",
    "                                   horizontal_flip=False,\n",
    "                                   vertical_flip=False,\n",
    "                                   brightness_range=[0.5, 1.5])\n",
    "    \n",
    "    for loc in os.listdir(parent):\n",
    "        i += 1\n",
    "        print(loc)\n",
    "        im = Image.open(image_folder_path+loc)   \n",
    "        im = im.resize((224, 224))\n",
    "        im_array = np.asarray(im)\n",
    "        X.append(im_array)\n",
    "        ID = loc.split(\"_\")\n",
    "        y.append(ID[0]+\"_\"+ID[1])\n",
    "        iter = image_gen.flow(np.expand_dims(im, 0))\n",
    "\n",
    "        for _ in range(extend_by):\n",
    "            X.append(np.asarray(next(iter)[0].astype(np.uint8)))\n",
    "            # ID = loc.split(\"_\")\n",
    "            y.append(ID[0]+\"_\"+ID[1])\n",
    "\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    return [X, y]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "first-multimedia",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sapphire-martial",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract embeddings of a face using model\n",
    "def extract_embedding(face, model):\n",
    "    img_data = face.astype('float32')\n",
    "    img_data = expand_dims(img_data, axis=0)\n",
    "    img_data = preprocess_input(img_data)\n",
    "    vgg16_feature = model.predict(img_data)    \n",
    "    return vgg16_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "yellow-jackson",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEmbeddings(trainX, testX):\n",
    "    global model\n",
    "    i = -1\n",
    "    newTrainX = []\n",
    "    for face in trainX:\n",
    "        i += 1 \n",
    "        if i%100 == 0: \n",
    "            print(i/100, end = ' ')\n",
    "        embedding = extract_embedding(face, model)\n",
    "        newTrainX.append(embedding.flatten())\n",
    "    newTrainX = asarray(newTrainX)\n",
    "    print('')\n",
    "    print(newTrainX.shape)\n",
    "\n",
    "    i = -1\n",
    "    newTestX = []\n",
    "    for face in testX:\n",
    "        i += 1\n",
    "        if i%100 == 0: \n",
    "            print(i/100, end = ' ')\n",
    "        embedding = extract_embedding(face, model)\n",
    "        newTestX.append(embedding.flatten())\n",
    "    newTestX = asarray(newTestX)\n",
    "    print('')\n",
    "    print(newTestX.shape)\n",
    "    \n",
    "    return newTrainX, newTestX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "blocked-definition",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to get left/right eye regions points\n",
    "def getRegion(eye, y1, y2, x1, x2):\n",
    "    w, h = x2-x1, y2-y1\n",
    "    ex1, ey1, w1, h1 = eye\n",
    "\n",
    "    if (x1 < ex1 < x1+w//2) and (x1 < ex1 + w1 < x1+w//2): \n",
    "        return 1, w1*h1\n",
    "    else:\n",
    "        return 2, w1*h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "lesser-section",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function which takes person ID and path where image has to be saved and number to images to be taken and captures images through webcam \n",
    "def getPersonImages(ID, path, imcount):\n",
    "    eye_cascade = cv2.CascadeClassifier('./haarcascade_eye.xml')\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    i = 0\n",
    "    while True:\n",
    "        ret, img = cap.read()\n",
    "        #gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        #cv2.imshow('img',img)\n",
    "        y1, y2 = 150, 300\n",
    "        x1, x2 = 150, 450\n",
    "        new_img = img[y1:y2, x1:x2]\n",
    "        cv2.rectangle(img,(x1,y1),(x2, y2),(255,0,0),1)\n",
    "        cv2.line(img, ((x1+x2)//2, y1), ((x1+x2)//2, y2), (0, 0, 255), 1)\n",
    "\n",
    "        eyes = eye_cascade.detectMultiScale(new_img, 1.3, 1)\n",
    "\n",
    "\n",
    "        if (len(eyes) == 2):\n",
    "            r1, a1 = getRegion(eyes[0], y1, y2, x1, x2)\n",
    "            r2, a2 = getRegion(eyes[1], y1, y2, x1, x2)\n",
    "\n",
    "            # for (ex,ey,ew,eh) in eyes:\n",
    "            #     ex += x1\n",
    "            #     ey += y1\n",
    "            #     cv2.rectangle(img,(ex,ey),(ex+ew,ey+eh),(255,255,255),1)\n",
    "\n",
    "            if (r1 != r2) and (a1 >= 6500 and a2 >= 6500):\n",
    "                cv2.rectangle(img,(x1,y1),(x2, y2),(0,255,0),1)\n",
    "                if i < imcount:\n",
    "                    i += 1\n",
    "                    cv2.imwrite(path + ID + '_L_' +str(i)+'.jpg',new_img[1:,1:(x2-x1)//2])\n",
    "                    cv2.imwrite(path + ID + '_R_' +str(i)+'.jpg',new_img[1:,(x2-x1)//2 +1:])\n",
    "                else:\n",
    "                    cap.release()\n",
    "                    cv2.destroyAllWindows()\n",
    "                    break\n",
    "        else:\n",
    "            cv2.rectangle(img,(x1,y1),(x2, y2),(0,0,255),1)\n",
    "\n",
    "        cv2.imshow('img',img)\n",
    "        k = cv2.waitKey(30) & 0xff\n",
    "        if k == 27:        \n",
    "            break\n",
    "getPersonImages(\"1234\",\"./temp/\",2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "accredited-shadow",
   "metadata": {},
   "outputs": [],
   "source": [
    "#funtion taking l and r images of eyes and giving label output and confidence\n",
    "def getPredictionCat(Lsample, Rsample, modelL, modelR):\n",
    "    Lp = modelL.predict(Lsample.reshape(1,-1))[0]\n",
    "    Ltop_values_index = sorted(range(len(Lp)), key=lambda i: Lp[i])[-5:]\n",
    "    Ltop_values = [Lp[i] for i in argsort(Lp)[-5:]]\n",
    "\n",
    "    probs = defaultdict(int)\n",
    "    for clas, prob in zip(Ltop_values_index, Ltop_values):\n",
    "        probs[clas] += prob\n",
    "\n",
    "\n",
    "    Rp = modelR.predict(Rsample.reshape(1,-1))[0]\n",
    "    Rtop_values_index = sorted(range(len(Rp)), key=lambda i: Rp[i])[-5:]\n",
    "    Rtop_values= [Rp[i] for i in argsort(Rp)[-5:]]\n",
    "\n",
    "    for clas, prob in zip(Rtop_values_index, Rtop_values):\n",
    "        probs[clas] += prob\n",
    "\n",
    "    mx_conf = 0\n",
    "    plabel = -1\n",
    "    for clas, prob in probs.items():\n",
    "        if prob > mx_conf:\n",
    "            mx_conf = prob\n",
    "            plabel = clas\n",
    "\n",
    "    confidence = mx_conf*0.5\n",
    "    \n",
    "    return (plabel, confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "empty-scene",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort the parts for easy reduction of samples per label.\n",
    "from numpy import asarray\n",
    "def makeParts(trainX, trainy, testX, testy):\n",
    "    zeepTest = sorted(list(zip(testy, testX)), key = lambda x: int(x[0].split('_')[0]))\n",
    "    zeepTrain = sorted(list(zip(trainy, trainX)), key = lambda x: int(x[0].split('_')[0]))\n",
    "    trainx = [x for y, x in zeepTrain[:]]\n",
    "    trainy = [y for y, x in zeepTrain[:]]\n",
    "    testx = [x for y, x in zeepTest[:]]\n",
    "    testy = [y for y, x in zeepTest[:]]\n",
    "\n",
    "    return asarray(trainx), asarray(trainy), asarray(testx), asarray(testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "vocal-prototype",
   "metadata": {},
   "outputs": [],
   "source": [
    "#final function to recognise a person\n",
    "def recognisePerson():\n",
    "    modelR = load_model('Trained models/modelR.h5')\n",
    "    modelL = load_model('Trained models/modelL.h5')\n",
    "\n",
    "    # dummy ID\n",
    "    getPersonImages(\"1234\",\"./temp/new_img/current/\",1)\n",
    "\n",
    "\n",
    "    # Only do the preprocess\n",
    "    ntestX, ntesty = extendDataset('temp/new_img/current/', 0)\n",
    "    ntestX, _ = getEmbeddings(ntestX, [])\n",
    "\n",
    "    encoderL = LabelEncoder()\n",
    "    encoderL.classes_ = load('Latest models/classesL.npy')\n",
    "    encoderR = LabelEncoder()\n",
    "    encoderR.classes_ = load('Latest models/classesR.npy')\n",
    "    \n",
    "    label, prob = getPredictionCat(ntestX[0], ntestX[1], modelL, modelR) \n",
    "    if prob >= 0.75:\n",
    "        l, r, p = [encoderL.inverse_transform([label]), encoderR.inverse_transform([label]), prob]\n",
    "        if l[0][:-2] != r[0][:-2]:\n",
    "            return(\"Model Corrupted!\")\n",
    "        else:\n",
    "            return(l[0][:-2]+ \" Confidence: \" + str(p))\n",
    "    else:\n",
    "        return(\"Not recognised:\", prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "entitled-berry",
   "metadata": {},
   "outputs": [],
   "source": [
    "#final function to register a new person using webcam\n",
    "def registerNewPerson():\n",
    "    # Load the old model\n",
    "    modelR = load_model('Trained models/modelR.h5')\n",
    "    modelL = load_model('Trained models/modelL.h5')\n",
    "    # load old dataset\n",
    "    data = load('temp/embeddings.npz')\n",
    "    trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
    "    trainX, trainy, testX, testy = list(trainX), list(trainy), list(testX), list(testy)\n",
    "    \n",
    "\n",
    "    # Add new data into the model\n",
    "    getPersonImages('1234', 'temp/img/test/', 1)\n",
    "    getPersonImages('1234', 'temp/img/train/', 1)\n",
    "\n",
    "    ntestX, ntesty = extendDataset('temp/img/test/', 1)\n",
    "    ntrainX, ntrainy = extendDataset('temp/img/train/', 5)\n",
    "    ntestX, ntrainX = getEmbeddings(ntestX, ntrainX)\n",
    "\n",
    "    savetrainX, savetrainy, savetestX, savetesty =  trainX + list(ntrainX), trainy + list(ntrainy), testX + list(ntestX), testy + list(ntesty)\n",
    "    savez_compressed('temp/latest_embeddings.npz', savetrainX, savetrainy, savetestX, savetesty)\n",
    "\n",
    "    new_data = [ntrainX, ntrainy, ntestX, ntesty]\n",
    "    modelL, modelR, trainX, trainy, testX, testy = addNewLabel(modelL, modelR, trainX, trainy, testX, testy, new_data)\n",
    "\n",
    "    RtrainX, Rtrainy, RtestX, Rtesty, LtrainX, Ltrainy, LtestX, Ltesty = seperate(trainX, trainy, testX, testy)\n",
    "\n",
    "    RtrainX, Rtrainy, RtestX, Rtesty = makeParts(RtrainX, Rtrainy, RtestX, Rtesty)\n",
    "    LtrainX, Ltrainy, LtestX, Ltesty = makeParts(LtrainX, Ltrainy, LtestX, Ltesty)\n",
    "\n",
    "    RtrainX, Rtrainy, RtestX, Rtesty, encoderR = encodeLabels(RtrainX, Rtrainy, RtestX, Rtesty)\n",
    "    LtrainX, Ltrainy, LtestX, Ltesty, encoderL = encodeLabels(LtrainX, Ltrainy, LtestX, Ltesty)\n",
    "\n",
    "    modelL = trainUpdatedModel(modelL, LtrainX, Ltrainy, LtestX, Ltesty)\n",
    "    modelR = trainUpdatedModel(modelR, RtrainX, Rtrainy, RtestX, Rtesty)\n",
    "\n",
    "    save('Latest models/classesL.npy', encoderL.classes_)\n",
    "    save('Latest models/classesR.npy', encoderR.classes_)\n",
    "    modelR.save('Latest models/modelR.h5') \n",
    "    modelL.save('Latest models/modelL.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "impaired-champagne",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seperate tean and test arrays of L and R images\n",
    "def seperate(trainX, trainy, testX, testy):\n",
    "\tLtrainX = []\n",
    "\tLtrainy = []\n",
    "\n",
    "\tRtrainX = []\n",
    "\tRtrainy = []\n",
    "\n",
    "\tRtestX = []\n",
    "\tRtesty = []\n",
    "\n",
    "\tLtestX = []\n",
    "\tLtesty = []\n",
    "\n",
    "\tfor x, y in zip(trainX, trainy):\n",
    "\t    if y.split('_')[-1] == 'L':\n",
    "\t        LtrainX.append(x)\n",
    "\t        Ltrainy.append(y)\n",
    "\t    else:\n",
    "\t        RtrainX.append(x)\n",
    "\t        Rtrainy.append(y)\n",
    "\n",
    "\tfor x, y in zip(testX, testy):\n",
    "\t    if y.split('_')[-1] == 'L':\n",
    "\t        LtestX.append(x)\n",
    "\t        Ltesty.append(y)\n",
    "\t    else:\n",
    "\t        RtestX.append(x)\n",
    "\t        Rtesty.append(y)\n",
    "\n",
    "\treturn RtrainX, Rtrainy, RtestX, Rtesty, LtrainX, Ltrainy, LtestX, Ltesty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "distributed-kitty",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit for new label classification\n",
    "def trainUpdatedModel(model, trainX, trainy, testX, testy):\n",
    "    Y_train = to_categorical(trainy)\n",
    "    Y_test = to_categorical(testy)\n",
    "    \n",
    "    t1 = time.time()\n",
    "    _history = model.fit(asarray(trainX), Y_train,validation_data = (asarray(testX),Y_test), epochs=50, batch_size=64)\n",
    "    t2 = time.time()\n",
    "\n",
    "    print(\"Time taken:\", t2-t1)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "separate-pathology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Choice: \n",
      "1. Register new person. \n",
      "2. Recognise person.\n",
      "2\n",
      "1234_L_1.jpg\n",
      "1234_R_1.jpg\n",
      "0.0 \n",
      "(2, 25088)\n",
      "\n",
      "(0,)\n",
      "('Not recognised:', 0.5)\n"
     ]
    }
   ],
   "source": [
    "choice = int(input(\"Enter Choice: \\n1. Register new person. \\n2. Recognise person.\\n\"))\n",
    "if choice == 1:\n",
    "\tregisterNewPerson()\n",
    "elif choice == 2:\n",
    "\tprint(recognisePerson())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spanish-banks",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu",
   "language": "python",
   "name": "tfgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
